{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16da8bfc-2ca5-4eed-9cca-7bf903c23448",
   "metadata": {},
   "source": [
    "### Use K means with k = 3 and perform clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc9fb8bc-d838-4bb1-810b-2d2feb2b7c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "np.warnings = warnings\n",
    "\n",
    "df_clustering_name = f'INTERPRETABLE_xmeans_TOXIC_NON_TOXIC_DIVISION_embeddings_CONCAT_3.csv' #this contains the clustering results\n",
    "df_classification_name = f'INTERPRETABLE_xmeans_TOXIC_NON_TOXIC_DIVISION_interpretable_CONCAT.csv' #this contains the classification results\n",
    "\n",
    "df_clustering = pd.read_csv(df_clustering_name)\n",
    "df_classification = pd.read_csv(df_classification_name)\n",
    "\n",
    "#The same process below can  be repeated considering averaged embeddings instead of conctenation and using the inteprretable features directly\n",
    "\n",
    "#df_clustering_name = f'INTERPRETABLE_xmeans_TOXIC_NON_TOXIC_DIVISION_embeddings_AVG_3.csv'\n",
    "#df_classification_name = f'INTERPRETABLE_xmeans_TOXIC_NON_TOXIC_DIVISION_interpretable_AVG_3.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7f3d44b-5f4c-487f-a144-31ce5aca8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification_toxic = df_classification[df_classification.TOXICITY == 'toxic'].drop(columns = ['CLUSTER', 'TOXICITY'])\n",
    "df_clustering_toxic = df_clustering[df_clustering.TOXICITY == 'toxic'].drop(columns = ['CLUSTER', 'TOXICITY'])\n",
    "\n",
    "df_classification_safe = df_classification[df_classification.TOXICITY != 'toxic'].drop(columns = ['CLUSTER', 'TOXICITY'])\n",
    "df_clustering_safe = df_clustering[df_clustering.TOXICITY != 'toxic'].drop(columns = ['CLUSTER', 'TOXICITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd051ae7-4fa9-44b0-9cbf-492588d33b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "initial_centers = kmeans_plusplus_initializer(df_clustering_toxic.values, 3, random_state  = random_state).initialize()\n",
    "\n",
    "centroid_clustering_method_instance = kmeans(df_clustering_toxic.values, initial_centers, random_state = random_state )\n",
    "centroid_clustering_method_instance.process()\n",
    "\n",
    "clusters = centroid_clustering_method_instance.get_clusters() \n",
    "centers = centroid_clustering_method_instance.get_centers()\n",
    "\n",
    "inertia = calculate_inertia(df_clustering_toxic.values, clusters, centers)\n",
    "sil = calculate_silhouette(df_clustering_toxic.values, clusters, centers)\n",
    "predictions = np.empty(len(df_clustering_toxic.values), dtype=int)\n",
    "\n",
    "\n",
    "for cluster_index, cluster in enumerate(clusters):\n",
    "\n",
    "    predictions[cluster] = cluster_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc5c3ad-9930-4503-863a-c1aa4974670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_toxic = []\n",
    "for index in range(len(df_clustering_toxic.values)):\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        if index in cluster:\n",
    "            preds_toxic += [str(i) +'_tox']\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485bbd23-3c27-4584-b4c9-1176332a904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "initial_centers = kmeans_plusplus_initializer(df_clustering_safe.values, k, random_state  = random_state).initialize()\n",
    "\n",
    "centroid_clustering_method_instance = kmeans(df_clustering_safe.values, initial_centers, random_state = random_state )\n",
    "centroid_clustering_method_instance.process()\n",
    "\n",
    "clusters = centroid_clustering_method_instance.get_clusters() \n",
    "centers = centroid_clustering_method_instance.get_centers()\n",
    "\n",
    "inertia = calculate_inertia(df_clustering_safe.values, clusters, centers)\n",
    "sil = calculate_silhouette(df_clustering_safe.values, clusters, centers)\n",
    "predictions = np.empty(len(df_clustering_safe.values), dtype=int)\n",
    "\n",
    "for cluster_index, cluster in enumerate(clusters):\n",
    "   \n",
    "    predictions[cluster] = cluster_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b8df0e-2590-4f1f-ade9-66c2e3efe232",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_safe = []\n",
    "for index in range(len(df_clustering_safe.values)):\n",
    "    for i, cluster in enumerate(merged_clusters):\n",
    "        if index in cluster:\n",
    "            preds_safe += [str(i) +'_safe']\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ad7e0-3ca5-421f-9497-fc6d7eeb8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two DataFrames\n",
    "df_complete = pd.concat([df_clustering_toxic, df_clustering_safe], axis=0, ignore_index=True)\n",
    "df_complete['cluster_preds'] = list(preds_toxic) + list(preds_safe)\n",
    "\n",
    "dict_toxic_safe = {k: i for i, k in enumerate(set(df_complete['cluster_preds']))}\n",
    "\n",
    "df_complete.to_csv('clustering_concat_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
