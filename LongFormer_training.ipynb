{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d8f703-1f5b-40f5-9d9a-38b0ffde3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce505da-f9ec-46d4-ab56-b9bef20d7399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import DatasetDict, Dataset\n",
    "from transformers import LongformerTokenizerFast, LongformerForSequenceClassification, Trainer, TrainingArguments, LongformerConfig\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf71efc4-7483-434e-8f7e-89a69074b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['agreeableness', 'openness', 'conscientiousness', 'extraversion','neuroticism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b96379ac-1166-490e-ba40-07b3129e4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df = pd.read_parquet('PANDORA_author_profiles.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ec68f01-fe61-4607-ab01-15f77fb4796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = pd.read_parquet('authors_full_text.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89d8095-a699-4149-b563-558ad0902ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_full_text_join = pd.merge(authors_df, full_text, on='author', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94b38aad-f3af-4d99-b857-6fba5dfdf6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_target = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59374d73-9dbd-4b98-8db5-5b64776176e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neuroticism'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = targets[id_target]\n",
    "target #use different targets for training on  different personality traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a085e8e-9827-450d-95fe-55332b84f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e40a883b-21cf-421d-8b24-711cb4361267",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_full_text_join_cleaned = author_full_text_join.dropna(subset=[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29ca5657-b8bb-4cc6-a67d-4433b3d31980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        Your first and second question is the same que...\n",
       "6        I've been asked to cum everywhere with my ex j...\n",
       "7        I'm currently in the middle of making a Payday...\n",
       "8        First and foremost I extend my condolences to ...\n",
       "23       I failed both...I'm great at reading people ir...\n",
       "                               ...                        \n",
       "10290    Hakuna Matata man. The problem free philosophy...\n",
       "10291    How has no one mentioned [Gerkin's](http://www...\n",
       "10292    What should we do? I knew it from the moment I...\n",
       "10293    TYPE_MENTION for morals and emotional toleranc...\n",
       "10294    YES. my god, thank you haha It could be that y...\n",
       "Name: full_text, Length: 1603, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_full_text_join_cleaned['full_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce559711-cc5e-4db5-b902-12bb7a7e6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_text_into_batches(text, batch_size=max_length * 5):\n",
    "    words = text.split()\n",
    "    \n",
    "    batches = [words[i:i + batch_size] for i in range(0, len(words), batch_size)]\n",
    "    \n",
    "    batches = [' '.join(batch) for batch in batches]\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2ed7cd4-8d81-493b-af0c-3d66f640a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "y_values = []\n",
    "batches_tot = []\n",
    "\n",
    "for i, row in author_full_text_join_cleaned.iterrows():\n",
    "    batches = divide_text_into_batches(row['full_text'])\n",
    "    target_values = [row[target] for x in range(len(batches))]\n",
    "    texts += batches\n",
    "    batches_tot.append(batches)\n",
    "    y_values += target_values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "642c0f0e-ec87-4ca5-8e2c-1d44f54d1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#texts = (texts[0:5000])\n",
    "#y_values =  (y_values[0:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a6cf12d-b7bf-4c90-b8f1-d222e48bc861",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 20, 40, 60, 80, 101]  # note: upper bound of the last bin is 101 to include 100\n",
    "labels = [0, 1, 2, 3, 4]\n",
    "\n",
    "# classify the values into bins\n",
    "categories = np.digitize(y_values, bins, right=False) - 1  # -1 to shift to zero-based indexing\n",
    "\n",
    "# map bin indices to labels\n",
    "classified_values = [labels[i] for i in categories]\n",
    "\n",
    "y = classified_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3001be60-502b-4525-b439-743861ca8785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2585244  0.14888301 0.19826573 0.16240447 0.2319224 ]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y, return_counts=True)[1] / len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abc4681f-8ffa-495f-8d1c-73be5197c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(texts)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db554293-63a5-4284-95af-e890629dfc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y) , test_size=0.3, stratify=y, random_state=42)\n",
    "#X_train, X_val, y_train, y_val = train_test_split(np.array(X_train), np.array(y_train) , test_size=0.1, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a9d7903-4255-44c8-8072-c865dc011749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4762"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c91428b8-b6f2-420f-8d4e-4093bb811ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DatasetDict()\n",
    "ds['train'] = Dataset.from_pandas(pd.DataFrame({'text' : X_train, 'label' : y_train}))\n",
    "ds['test'] =  Dataset.from_pandas(pd.DataFrame({'text' : X_test, 'label' : y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f9f7414-e802-40ed-9cb4-94a717a60c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acascione/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load model and tokenizer and define length of the text sequence\n",
    "\n",
    "max_length = 4096\n",
    "\n",
    "model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096',\n",
    "                                                           gradient_checkpointing=False,\n",
    "                                                           attention_window = 512,\n",
    "                                                           num_labels = len(set(y)))\n",
    "                                                 \n",
    "\n",
    "tokenizer = LongformerTokenizerFast.from_pretrained('allenai/longformer-base-4096', max_length = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54dbdae-8102-416c-8ffa-9d9bf9d31822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that will tokenize the model, and will return the relevant inputs for the model\n",
    "def tokenization(batched_text):\n",
    "    return tokenizer(batched_text['text'], padding = 'max_length', truncation=True, max_length = max_length)\n",
    "\n",
    "train_data = ds['train'].map(tokenization)\n",
    "test_data = ds['test'].map(tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c42aa863-a2de-4b37-b287-03f5d3b7f6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we make sure our truncation strateging and the padding are set to the maximung length\n",
    "len(train_data['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9459dc6c-4a29-4d5a-b2c2-586b76516a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_data.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af18733d-3850-4e08-97dd-8979c6a504f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define accuracy metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # argmax(pred.predictions, axis=1)\n",
    "    #pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02caf1-7d8c-4564-a24e-45d85fbd84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Your training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = f'./{target}/output_dir',\n",
    "    num_train_epochs = 5,\n",
    "    per_device_train_batch_size = 8,\n",
    "    gradient_accumulation_steps = 32,    \n",
    "    per_device_eval_batch_size = 16,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    disable_tqdm = False, \n",
    "    load_best_model_at_end=True,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps = 4,\n",
    "    save_strategy = 'epoch',\n",
    "    fp16 = True,\n",
    "    logging_dir= f'./{target}/data_files',\n",
    "    dataloader_num_workers = 0,\n",
    "    run_name = f'{target}_longformer-classification-updated-rtx3090_paper_replication_2_warm'\n",
    ")\n",
    "\n",
    "# Define the Trainer class\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, model, args, train_dataset=None, eval_dataset=None, compute_metrics=None):\n",
    "        super().__init__(model=model, args=args, train_dataset=train_dataset, eval_dataset=eval_dataset, compute_metrics=compute_metrics)\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        for epoch in range(int(self.args.num_train_epochs)):\n",
    "            for step, batch in enumerate(self.get_train_dataloader()):\n",
    "                # Move the batch to the device\n",
    "                batch = {k: v.to(self.device).to('cuda') for k, v in batch.items()}\n",
    "                outputs = self.model(**batch)\n",
    "                loss = outputs.loss\n",
    "                loss.backward()\n",
    "\n",
    "                if (step + 1) % self.args.gradient_accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.scheduler.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                if step % self.args.logging_steps == 0:\n",
    "                    print(f'Epoch: {epoch}, Step: {step}, Loss: {loss.item()}')\n",
    "\n",
    "# Instantiate the trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1987287-e583-41a6-80cc-ba5e896866fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = f'./{target}/output_dir',\n",
    "    num_train_epochs = 5,\n",
    "    per_device_train_batch_size = 8,\n",
    "    gradient_accumulation_steps = 16,    \n",
    "    per_device_eval_batch_size= 16,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    disable_tqdm = False, \n",
    "    load_best_model_at_end=True,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps = 4,\n",
    "    save_strategy = 'epoch',\n",
    "    fp16 = True,\n",
    "    logging_dir= f'./{target}/data_files',\n",
    "    dataloader_num_workers = 0,\n",
    "    run_name = f'{target}_longformer-classification-updated-rtx3090_paper_replication_2_warm',\n",
    "    #no_cuda = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "357393d1-eb80-4b44-ae30-64331da3244f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the trainer class and check for available devices\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data\n",
    ")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09658ab-cbc2-474d-945d-8b3d101b20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d2ada5-f25a-4c4f-ab58-0eb178f44917",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(f'./{target}/model_saved/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56566d59-1056-464e-b2a7-86a52f0103db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec8185-6eb6-4964-a3f5-5bf799be1cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
