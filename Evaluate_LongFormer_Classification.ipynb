{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa82764e-7ad3-4777-98a0-c487406171f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c0163c0-6745-4ec4-94b5-5e869d7266c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import DatasetDict, Dataset\n",
    "from transformers import LongformerTokenizerFast, LongformerForSequenceClassification, Trainer, TrainingArguments, LongformerConfig, AutoTokenizer\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06813c77-88d6-46fe-9410-46b302a963d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['agreeableness', 'openness', 'conscientiousness', 'extraversion','neuroticism']\n",
    "\n",
    "max_length = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e04de39-1fbf-46bb-985f-1c3aa7a2de4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraversion\n"
     ]
    }
   ],
   "source": [
    "target = targets[3]\n",
    "print(target) #change this for other classifcations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf3450c5-8b36-4ea1-8601-3db510e3106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df = pd.read_parquet('PANDORA_author_profiles.parquet')\n",
    "full_text = pd.read_parquet('authors_full_text.parquet')\n",
    "\n",
    "author_full_text_join = pd.merge(authors_df, full_text, on='author', how='inner')\n",
    "author_full_text_join_cleaned = author_full_text_join.dropna(subset=[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec718bc-904a-48c9-abcb-5fcb7c22f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_complete = pd.read_parquet('sample_comments/reddit_complete_NO_LANG.parquet') #consider the full text for each author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae719ab3-7b61-41a2-97a5-42f406e6a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "reddit_complete = pd.read_parquet('sample_comments/reddit_complete_NO_LANG.parquet')\n",
    "\n",
    "authors = []\n",
    "texts = []\n",
    "\n",
    "# Iterate over each unique author in the DataFrame\n",
    "for author in set(reddit_complete.author):\n",
    "    # Concatenate all texts for the current author\n",
    "    full_text = ' '.join(reddit_complete[reddit_complete.author == author].text)\n",
    "    \n",
    "    # Append author and their full concatenated text to the lists\n",
    "    authors.append(author)\n",
    "    texts.append(full_text)\n",
    "\n",
    "# Create DataFrame with authors and concatenated texts\n",
    "df_full_text = pd.DataFrame({\n",
    "    'author': authors,\n",
    "    'full_text': texts\n",
    "})\n",
    "\n",
    "df_full_text.to_parquet('authors_generated_full_text.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "304085e1-322d-429a-b243-fce4e08261bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_text_into_batches(text, batch_size=max_length * 5):\n",
    "    words = text.split()\n",
    "    \n",
    "    batches = [words[i:i + batch_size] for i in range(0, len(words), batch_size)]\n",
    "    \n",
    "    batches = [' '.join(batch) for batch in batches]\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9c20ee5-8348-445e-811a-1d4ca8935477",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "y_values = []\n",
    "authors = []\n",
    "\n",
    "for i, row in author_full_text_join_cleaned.iterrows():\n",
    "    batches = divide_text_into_batches(row['full_text'])\n",
    "    target_values = [row[target] for x in range(len(batches))]\n",
    "    texts += batches\n",
    "    authors += [row['author'] for x in range(len(batches))]\n",
    "    y_values += target_values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb96ffcc-006b-47b7-9b21-3b0e40b10217",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 20, 40, 60, 80, 101]  # Note: upper bound of the last bin is 101 to include 100\n",
    "labels = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Classify the values into bins\n",
    "categories = np.digitize(y_values, bins, right=False) - 1  # -1 to shift to zero-based indexing\n",
    "\n",
    "# Map bin indices to labels\n",
    "classified_values = [labels[i] for i in categories]\n",
    "\n",
    "y = classified_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4498285d-2650-4fdc-bf0a-42b6dac48630",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = texts\n",
    "y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd6644f4-d04c-4cef-9c93-dc13924c6a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6818"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4411eb8-dcc5-48f0-a3d7-4fa946d33948",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y) , test_size=0.3, stratify=y, random_state=42)\n",
    "#X_train, X_val, y_train, y_val = train_test_split(np.array(X_train), np.array(y_train) , test_size=0.1, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6c72fb9-82af-4130-a81c-8650f6a42c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DatasetDict()\n",
    "\n",
    "ds['test'] = Dataset.from_pandas(pd.DataFrame({'text' : np.array(X_test), 'label' : np.array(y_test)}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "071b608f-c9ab-4059-8e6a-94bea256b1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acascione/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_base = LongformerForSequenceClassification.from_pretrained(f'PwNzDust/{target}_model', token = 'token_here',\n",
    "                                                           gradient_checkpointing=False,\n",
    "                                                           attention_window = 512,\n",
    "                                                           num_labels = len(set(y)),\n",
    "                                                           max_length = max_length)\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = LongformerTokenizerFast.from_pretrained('allenai/longformer-base-4096', max_length = max_length, model_max_length = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bef57d84-5f5e-4425-a0be-1365e4a4d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input texts\n",
    "def tokenization(batched_text):\n",
    "    return tokenizer(batched_text['text'], padding = 'max_length', truncation=True, max_length = max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb32cb71-6dcf-4685-87eb-505a39247837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c71f46fb8b4ba78fcdcd945df3e1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2046 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = ds['test'].map(tokenization, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1485218-f868-408e-81be-903e93423c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "auths_test = [auth for auth, text in zip(authors, texts) if text in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfa95d43-0014-4c0f-94f1-569f81db5035",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26d5924e-8c16-41bc-b2d9-2105ef715204",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "223b56ea-7df1-4492-a19a-55ebe7624d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerForSequenceClassification(\n",
       "  (longformer): LongformerModel(\n",
       "    (embeddings): LongformerEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "    )\n",
       "    (encoder): LongformerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): LongformerClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_base.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a43400b4-2de2-4a22-a16a-093f9c8fed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ca3a4d3-7260-4521-9195-a42029ffd461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing global attention on CLS token...\n"
     ]
    }
   ],
   "source": [
    "# Function to make predictions without batching\n",
    "def predict(model, dataset):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            inputs = {key: dataset[i][key].unsqueeze(0).to(model.device) for key in dataset[i] if key != 'label'}\n",
    "            outputs = model(**inputs)\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "            predictions.append(preds.item())\n",
    "            #print(preds)\n",
    "    return predictions\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = predict(model_base, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd33ff05-f3a6-43a0-bb50-932eef4df99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation = pd.DataFrame({'text' : X_test, 'ground_truth' : y_test , 'pred' : predictions, 'author' : auths_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "465c2870-6115-4f3f-9f4b-998c459f8e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>pred</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jackboot-thug US civilian murdering American m...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-BigSexy-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fr as being a sexist.6. Thierry Baudet says th...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-BigSexy-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stack. Until we get the ultimate truth of the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-BigSexy-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for you, my dear. We won't let those monsters ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-CrestiaBell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>down as of noon GMT.~~Not down, just extremely...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-CrestiaBell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>of evidence relevant to me.and they're still d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pungens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>that is the domain of the FA (and FIFA to an e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>quakeroaks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>on account of immature/bad parents, which is n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>quakeroaks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>is pretty good too OH okay i understand now, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rrgjl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>you go and poop on them. Do I have an answer? ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>seldomvanilla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2046 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  ground_truth  pred  \\\n",
       "0     jackboot-thug US civilian murdering American m...             4     4   \n",
       "1     fr as being a sexist.6. Thierry Baudet says th...             2     0   \n",
       "2     stack. Until we get the ultimate truth of the ...             2     2   \n",
       "3     for you, my dear. We won't let those monsters ...             2     3   \n",
       "4     down as of noon GMT.~~Not down, just extremely...             4     4   \n",
       "...                                                 ...           ...   ...   \n",
       "2041  of evidence relevant to me.and they're still d...             0     0   \n",
       "2042  that is the domain of the FA (and FIFA to an e...             0     0   \n",
       "2043  on account of immature/bad parents, which is n...             0     0   \n",
       "2044  is pretty good too OH okay i understand now, h...             1     1   \n",
       "2045  you go and poop on them. Do I have an answer? ...             4     4   \n",
       "\n",
       "             author  \n",
       "0         -BigSexy-  \n",
       "1         -BigSexy-  \n",
       "2         -BigSexy-  \n",
       "3      -CrestiaBell  \n",
       "4      -CrestiaBell  \n",
       "...             ...  \n",
       "2041        pungens  \n",
       "2042     quakeroaks  \n",
       "2043     quakeroaks  \n",
       "2044          rrgjl  \n",
       "2045  seldomvanilla  \n",
       "\n",
       "[2046 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b534d840-c310-4acd-b9a6-e0e6948857b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation = pd.DataFrame({'text' : X_test, 'ground_truth' : y_test , 'pred' : predictions, 'author' : auths_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c440769f-1ac3-4f75-ab4e-75b1621ecb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'author' and calculate mode of 'ground-truth' and 'pred'\n",
    "mode_results = df_evaluation.groupby('author').agg(\n",
    "    ground_truth_mode=('ground_truth', lambda x: x.mode()[0]),\n",
    "    pred_mode=('pred', lambda x: x.mode()[0])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3bd1e1e-96e7-4293-af21-c55942efb226",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(model_base.pred_mode)\n",
    "labels = np.array(model_base.ground_truth_mode)\n",
    "\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "acc = accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "200edb26-6d0a-489b-aa3d-219fd443d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'accuracy': [acc],\n",
    "    'f1': [f1],\n",
    "    'precision': [precision],\n",
    "    'recall': [recall]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e3c8814-40fc-44bd-b975-a0c607bdea95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.735589</td>\n",
       "      <td>0.733535</td>\n",
       "      <td>0.736087</td>\n",
       "      <td>0.735589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy        f1  precision    recall\n",
       "0  0.735589  0.733535   0.736087  0.735589"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22166b0-8079-4e52-9e2a-427f3d990ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
